import os
import torch
import json
import numpy as np
from torch import nn
from torch.utils.data import DataLoader
from safetensors.torch import load_file
from transformers import AutoModelForCausalLM, AutoTokenizer
from tqdm import tqdm
from probing import LlamaWithClassifier, QADataset, MyCollator



# ── 1. 모델 & 체크포인트 로드 ─────────────────────────────────────────────────
ckpt_dir = "./probing/checkpoints/25_epochs/checkpoint-1575"
device = "cuda" if torch.cuda.is_available() else "cpu"


MODEL_NAME = "meta-llama/Llama-2-7b-hf"

model = LlamaWithClassifier(model_name=MODEL_NAME, output_dim=2)
weights = load_file(os.path.join(ckpt_dir, "model.safetensors"))
model.load_state_dict(weights)


model.half()  # FP16로 변환 (메모리 절약)

# 여러 GPU 사용 준비(DataParallel)
if torch.cuda.device_count() > 1:
    model = nn.DataParallel(model)
model.eval()
model.to(device)


# ── 2. Processor 준비 ─────────────────────────────────────────────────────────

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
tokenizer.padding_side = "left"  # 왼쪽 패딩
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token


# ── 3. 데이터 로드 & DataLoader ───────────────────────────────────────────────
data_path = 'dataset_test.json'
with open(data_path, "r", encoding="utf-8") as f:
    data = json.load(f)

# Dataset/Collator
dataset  = QADataset(data, tokenizer)
collator=  MyCollator(tokenizer, max_length=512)

loader = DataLoader(
    dataset,
    batch_size=32,           # 필요에 따라 조정
    shuffle=False,
    num_workers=6,
    collate_fn=collator,
    pin_memory=True,
)

# ── 4. Inference & 확률·예측 수집 ───────────────────────────────────────────────
all_probs  = []   # [[p0, p1], ...]
all_preds  = []   # [0/1, ...]
all_labels = []   # [0/1, ...]

with torch.no_grad():
    for batch in tqdm(loader, desc="Multi-GPU Inference"):
        # labels 분리
        labels = batch.pop("labels").to(device)
        # 남은 입력들 전부 device 로
        for k, v in batch.items():
            batch[k] = v.to(device)

        # forward 
        logits = model(**batch)
        probs  = torch.softmax(logits, dim=-1) 

        # CPU로 옮기고 리스트에 확장
        probs_cpu   = probs.cpu().tolist()
        labels_cpu  = labels.cpu().tolist()
        preds_batch = np.argmax(probs_cpu, axis=1).tolist()

        all_probs.extend(probs_cpu)
        all_preds.extend(preds_batch)
        all_labels.extend(labels_cpu)

# ── 5. Accuracy & ECE 계산 ──────────────────────────────────────────────────────
from sklearn.metrics import accuracy_score

acc = accuracy_score(all_labels, all_preds)
print(f"Overall Accuracy: {acc:.4f}")

def compute_ece(confidences, labels, n_bins=10):
    confidences = np.array(confidences)
    labels      = np.array(labels)
    bin_edges   = np.linspace(0.0, 1.0, n_bins+1)
    ece = 0.0
    for i in range(n_bins):
        mask = (confidences > bin_edges[i]) & (confidences <= bin_edges[i+1])
        if mask.sum() == 0:
            continue
        bin_conf = confidences[mask].mean()
        bin_acc  = labels[mask].mean()
        prop     = mask.sum() / len(confidences)
        ece     += np.abs(bin_acc - bin_conf) * prop
    return ece

max_confs = [max(p0, p1) for p0, p1 in all_probs]
ece = compute_ece(max_confs, all_labels, n_bins=10)
print(f"Expected Calibration Error (ECE): {ece:.4f}")

# ── 5. 결과 저장 ───────────────────────────────────────────────────────────────
out_dict = {
    "all_labels": all_labels,
    "max_confs":  max_confs,
    "all_probs": all_probs,
}

dir="probing_1575.json"
with open(dir, "w") as f:
    json.dump(out_dict, f)

print(f"Saved {len(all_labels)} labels + confidences to {dir}")
